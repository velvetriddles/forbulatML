import os
import json
from intent_classifier import IntentClassifier

try:
    import speech_recognition as sr
    SPEECH_AVAILABLE = True
except ImportError:
    print("–ú–æ–¥—É–ª—å speech_recognition –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤–≤–æ–¥.")
    print("–î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install SpeechRecognition")
    SPEECH_AVAILABLE = False

class SmartHomeAssistant:
    def __init__(self, model_path=None):
        self.classifier = IntentClassifier()
        
        # –°–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –∏–Ω—Ç–µ–Ω—Ç–æ–≤, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –º—ã –±—É–¥–µ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.supported_intents = [
            "light_on", "light_off", 
            "temperature_up", "temperature_down", 
            "music_on", "music_off",
            "door_lock", "door_unlock",
            "sensor_check", "sensor_reset",
            "unknown"
        ]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if model_path and os.path.exists(model_path):
            self.classifier.load_model(model_path)
        else:
            # –ò–Ω–∞—á–µ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            data_path = os.path.join('data', 'intents.json')
            self.classifier.train(data_path, epochs=10)
            
            # –ò —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ—ë
            if model_path:
                self.classifier.save_model(model_path)
                
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Ç–µ–Ω—Ç–∞
        self.actions = {
            "light_on": self.turn_light_on,
            "light_off": self.turn_light_off,
            "temperature_up": self.increase_temperature,
            "temperature_down": self.decrease_temperature,
            "music_on": self.play_music,
            "music_off": self.stop_music,
            "door_lock": self.lock_door,
            "door_unlock": self.unlock_door,
            "sensor_check": self.check_sensors,
            "sensor_reset": self.reset_sensors,
            "unknown": self.handle_unknown
        }
    
    # –°–∏–º—É–ª—è—Ü–∏–∏ –¥–µ–π—Å—Ç–≤–∏–π —É–º–Ω–æ–≥–æ –¥–æ–º–∞
    def turn_light_on(self):
        print("üîÜ –í–∫–ª—é—á–∞—é —Å–≤–µ—Ç!")
        
    def turn_light_off(self):
        print("üåë –í—ã–∫–ª—é—á–∞—é —Å–≤–µ—Ç!")
        
    def increase_temperature(self):
        print("üî• –£–≤–µ–ª–∏—á–∏–≤–∞—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É!")
        
    def decrease_temperature(self):
        print("‚ùÑÔ∏è –£–º–µ–Ω—å—à–∞—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É!")
        
    def play_music(self):
        print("üéµ –í–∫–ª—é—á–∞—é –º—É–∑—ã–∫—É!")
        
    def stop_music(self):
        print("üîá –í—ã–∫–ª—é—á–∞—é –º—É–∑—ã–∫—É!")
        
    def lock_door(self):
        print("üîí –ó–∞–∫—Ä—ã–≤–∞—é –¥–≤–µ—Ä—å –Ω–∞ –∑–∞–º–æ–∫!")
        
    def unlock_door(self):
        print("üîì –û—Ç–∫—Ä—ã–≤–∞—é –¥–≤–µ—Ä—å!")
        
    def check_sensors(self):
        print("üìä –ü—Ä–æ–≤–µ—Ä—è—é –¥–∞—Ç—á–∏–∫–∏...")
        print("  ‚úÖ –î–∞—Ç—á–∏–∫ –¥–≤–∏–∂–µ–Ω–∏—è: –Ω–∏–∫–æ–≥–æ –Ω–µ—Ç")
        print("  ‚úÖ –î–∞—Ç—á–∏–∫ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã: 22¬∞C")
        print("  ‚úÖ –î–∞—Ç—á–∏–∫ –≤–ª–∞–∂–Ω–æ—Å—Ç–∏: 45%")
        print("  ‚úÖ –î–∞—Ç—á–∏–∫ –¥—ã–º–∞: –Ω–æ—Ä–º–∞")
        print("  ‚úÖ –î–∞—Ç—á–∏–∫ –ø—Ä–æ—Ç–µ—á–∫–∏: —Å—É—Ö–æ")
        
    def reset_sensors(self):
        print("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞—é –≤—Å–µ –¥–∞—Ç—á–∏–∫–∏...")
        print("  ‚úÖ –î–∞—Ç—á–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        
    def handle_unknown(self):
        print("ü§î –ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —É–º–µ—é –≤—ã–ø–æ–ª–Ω—è—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É.")
    
    def recognize_speech(self):
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
        if not SPEECH_AVAILABLE:
            return None
            
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("–°–ª—É—à–∞—é...")
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source)
            
        try:
            text = recognizer.recognize_google(audio, language="ru-RU")
            print(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text}")
            return text
        except sr.UnknownValueError:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å")
            return None
        except sr.RequestError:
            print("–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏")
            return None
    
    def process_command(self, text):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if not text:
            return
            
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Ç–∞
        prediction = self.classifier.predict(text)
        intent = prediction["intent"]
        confidence = prediction["confidence"]
        
        print(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ–Ω—Ç: {intent} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –ª–∏ –∏–Ω—Ç–µ–Ω—Ç
        if intent not in self.supported_intents:
            print(f"‚ö†Ô∏è –ò–Ω—Ç–µ–Ω—Ç '{intent}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
            intent = "unknown"
            confidence = 0.0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –∏–Ω—Ç–µ–Ω—Ç–æ–≤
        
        # –¢–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ BERT –¥–æ–ª–∂–Ω–∞ –¥–∞–≤–∞—Ç—å –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å > 0.5
        if confidence > 0.5 and intent in self.actions:
            self.actions[intent]()
        else:
            # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è, —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞
            print("–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —É–≤–µ—Ä–µ–Ω, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å.")
            if "unknown" in self.actions:
                self.actions["unknown"]()
    
    def run_text_mode(self):
        """–ó–∞–ø—É—Å–∫ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ"""
        print("=== –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç —É–º–Ω–æ–≥–æ –¥–æ–º–∞ (—Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º) ===")
        print("–í–≤–µ–¥–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –∏–ª–∏ '–≤—ã—Ö–æ–¥' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")
        print("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∫–æ–º–∞–Ω–¥—ã:")
        print("  - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–≤–µ—Ç–æ–º (–≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å —Å–≤–µ—Ç)")
        print("  - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π (—Ç–µ–ø–ª–µ–µ/—Ö–æ–ª–æ–¥–Ω–µ–µ)")
        print("  - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º—É–∑—ã–∫–æ–π (–≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å)")
        print("  - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–µ—Ä—è–º–∏ (–æ—Ç–∫—Ä—ã—Ç—å/–∑–∞–∫—Ä—ã—Ç—å)")
        print("  - –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç—á–∏–∫–æ–≤ (–ø—Ä–æ–≤–µ—Ä–∏—Ç—å/—Å–±—Ä–æ—Å–∏—Ç—å)")
        
        while True:
            text = input("\n–í–∞—à–∞ –∫–æ–º–∞–Ω–¥–∞: ")
            if text.lower() in ["–≤—ã—Ö–æ–¥", "exit", "quit"]:
                break
                
            self.process_command(text)
    
    def run_voice_mode(self):
        """–ó–∞–ø—É—Å–∫ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º —Ä–µ–∂–∏–º–µ"""
        if not SPEECH_AVAILABLE:
            print("–ì–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º.")
            self.run_text_mode()
            return
            
        print("=== –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —É–º–Ω–æ–≥–æ –¥–æ–º–∞ ===")
        print("–°–∫–∞–∂–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –∏–ª–∏ '–≤—ã—Ö–æ–¥' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")
        
        while True:
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å
            text = self.recognize_speech()
            
            if not text:
                continue
                
            if "–≤—ã—Ö–æ–¥" in text.lower():
                break
                
            self.process_command(text)
            
if __name__ == "__main__":
    model_path = os.path.join('data', 'intent_model.pt')  # –ù–æ–≤–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è PyTorch
    assistant = SmartHomeAssistant(model_path)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
    if SPEECH_AVAILABLE:
        print("–î–æ—Å—Ç—É–ø–µ–Ω –≥–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º!")
        mode = input("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º (1 - —Ç–µ–∫—Å—Ç, 2 - –≥–æ–ª–æ—Å): ")
        if mode == "2":
            assistant.run_voice_mode()
        else:
            assistant.run_text_mode()
    else:
        assistant.run_text_mode() 